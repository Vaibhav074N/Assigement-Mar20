{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPK4C01yBC2KjklfuTnsgNG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaibhav074N/Assigement-Mar20/blob/main/Assigement_Mar20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is data encoding? How is it useful in data science?"
      ],
      "metadata": {
        "id": "a_VRn0Co_xzM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans:\n",
        "\n",
        "\n",
        "Data encoding, in the context of data science, refers to the process of converting categorical or textual data into a numerical format that can be easily processed by machine learning algorithms or other data analysis techniques. It is an essential step in data preprocessing as many machine learning algorithms require numerical input data. Data encoding allows data scientists to handle and utilize different types of data effectively in their analysis and modeling tasks.\n",
        "\n",
        "\n",
        "There are several types of data encoding techniques used in data science, depending on the nature of the data:-\n",
        "\n",
        "- Label Encoding\n",
        "- One-Hot Encoding\n",
        "- Ordinal Encoding\n",
        "- Binary Encoding\n",
        "- Hash Encoding\n",
        "\n",
        "\n",
        "Data encoding is useful in data science for several reasons:\n",
        "\n",
        "1.Handling Categorical Data: Many machine learning algorithms can only process numerical data. Data encoding allows us to represent categorical data in a numerical format, making it compatible with these algorithms.\n",
        "\n",
        "2.Reducing Memory Usage: Data encoding can be beneficial in reducing the memory usage of datasets. For example, one-hot encoding can convert a categorical feature with n categories into n binary features, which can be more memory-efficient.\n",
        "\n",
        "3.Improving Algorithm Performance: Converting data into a suitable numerical format can help improve the performance of machine learning algorithms. Algorithms often work better with numerical representations as they can process and interpret the data more effectively.\n",
        "\n",
        "4.Enabling Feature Engineering: Data encoding is a critical step in feature engineering, where new features are derived from existing data. It allows data scientists to create new numerical features based on categorical or textual data, which can improve the predictive power of machine learning models.\n",
        "\n",
        "In summary, data encoding is a crucial aspect of data preprocessing in data science. It enables the transformation of categorical or textual data into a numerical format that can be used effectively in various analysis and modeling tasks, making the data more accessible and compatible with machine learning algorithms."
      ],
      "metadata": {
        "id": "ZnHeR9F3D1-f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzmpPauC_c8O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What is nominal encoding? Provide an example of how you would use it in a real-world scenario."
      ],
      "metadata": {
        "id": "R_ZI-McU_0sT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans:\n",
        "\n",
        "Nominal encoding, also known as label encoding, is a type of data encoding used to convert categorical variables with no inherent order or rank into numerical labels. In nominal encoding, each category is assigned a unique integer label. It is typically used when dealing with nominal categorical data, where there is no meaningful order among the categories.\n",
        "\n",
        "Example of Nominal Encoding:\n",
        "\n",
        "Let's consider a real-world scenario where we have a dataset of car models and their corresponding body types. The body types are nominal categorical variables because they do not have any inherent order.\n",
        "\n",
        "To apply nominal encoding to the \"Body Type\" feature, we would convert each body type category into a unique integer label\n",
        "\n",
        "In this example, the \"Body Type\" feature has been encoded into numerical labels (0, 1, 2, 3) using nominal encoding. The mapping of each body type to a unique integer label is arbitrary and does not imply any order among the categories. This numerical representation allows us to use the \"Body Type\" feature in machine learning algorithms, which typically require numerical input.\n",
        "\n",
        "Nominal encoding is simple and straightforward to implement, but it's important to be aware that it may introduce unintended ordinality in the data. For instance, using nominal encoding on a feature like \"Color\" (e.g., Red, Green, Blue) may introduce an unintended ordering where one color's label is considered higher or lower than another color's label. In such cases, one-hot encoding may be preferred to avoid introducing any ordinality. The choice of encoding technique depends on the nature of the data and the requirements of the analysis or modeling task."
      ],
      "metadata": {
        "id": "WW5CMB14EzoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "data = {\n",
        "    'Car Model': ['Honda Civic', 'Toyota Camry', 'Ford F-150', 'Subaru Outback', 'Chevrolet Corvette'],\n",
        "    'Body Type': ['Sedan', 'Sedan', 'Truck', 'Wagon', 'Sports Car']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "df['Body Type (Encoded)'] = label_encoder.fit_transform(df['Body Type'])\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "pjXSheNG_0LN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac00be7-060f-403d-c868-9db2de03b724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Car Model   Body Type  Body Type (Encoded)\n",
            "0         Honda Civic       Sedan                    0\n",
            "1        Toyota Camry       Sedan                    0\n",
            "2          Ford F-150       Truck                    2\n",
            "3      Subaru Outback       Wagon                    3\n",
            "4  Chevrolet Corvette  Sports Car                    1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5l0KzC-eFfvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. In what situations is nominal encoding preferred over one-hot encoding? Provide a practical example."
      ],
      "metadata": {
        "id": "Px2CbjHD_4vt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans:\n",
        "\n",
        "Nominal encoding (label encoding) is preferred over one-hot encoding in situations where the categorical variable has a large number of unique categories or when there is a natural order or hierarchy among the categories. One-hot encoding creates binary columns for each category, which can lead to a significant increase in the dimensionality of the dataset and result in a sparse matrix. In such cases, nominal encoding can be a more efficient and practical choice.\n",
        "\n",
        "Practical Example:\n",
        "\n",
        "Let's consider a real-world scenario where we have a dataset of customer reviews for a product. One of the features is the sentiment of the review, which can be positive, neutral, or negative. The dataset looks like this:\n",
        "\n",
        "Review Text\t             |             Sentiment\n",
        "\n",
        "The product is great!      |  \t        Positive\n",
        "\n",
        "The product meets expectations.\t  |    Neutral\n",
        "\n",
        "The product is not as expected.\t  |    Negative\n",
        "\n",
        "Love the product!\t           |         Positive\n",
        "\n",
        "I don't like the product.\t    |        Negative\n",
        "\n",
        "\n",
        "In this example, the \"Sentiment\" feature is nominal categorical because the categories (Positive, Neutral, Negative) have no inherent order or rank.\n",
        "\n",
        "If we use one-hot encoding on the \"Sentiment\" feature, it would create three binary columns for each sentiment category, resulting in a sparse matrix:\n",
        "\n",
        "Review Text\t  |  Sentiment_Positive  |\tSentiment_Neutral  |\tSentiment_Negative\n",
        "\n",
        "The product is great!\t| 1             |     \t0            |      \t0\n",
        "\n",
        "The product meets expectations.\t|  0\t|       1            |    \t0\n",
        "\n",
        "The product is not as expected. |\t 0\t|       0             |     \t1\n",
        "\n",
        "Love the product!\t      |     1       |       \t0        |     \t0\n",
        "\n",
        "I don't like the product.\t |      0    |\t   0      |\t      1\n",
        "\n",
        "\n",
        "While one-hot encoding is useful for categorical data with a few unique categories, it may not be practical in this case because there are only three categories (Positive, Neutral, Negative). It would create three binary columns, increasing the dimensionality unnecessarily. In such cases, using nominal encoding is more efficient and less redundant.\n",
        "\n",
        "\n",
        "To apply nominal encoding to the \"Sentiment\" feature, we would convert each sentiment category into a unique integer label:\n",
        "\n",
        "Review Text\t                         Sentiment (Encoded)\n",
        "\n",
        "The product is great!\t                      1\n",
        "\n",
        "The product meets expectations.\t            2\n",
        "\n",
        "The product is not as expected.            \t0\n",
        "\n",
        "Love the product!\t                          1\n",
        "\n",
        "I don't like the product.\t                  0\n",
        "\n",
        "\n",
        "In this example, nominal encoding is a preferred choice because it is more practical and efficient, especially when the number of unique categories is small and there is no inherent order among the categories. The numerical representation allows us to use the \"Sentiment\" feature effectively in machine learning algorithms, without increasing the dimensionality of the dataset unnecessarily.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EslAUuojHWqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "data = {\n",
        "    'Review Text': ['The product is great!', 'The product meets expectations.', 'The product is not as expected.',\n",
        "                    'Love the product!', \"I don't like the product.\"],\n",
        "    'Sentiment': ['Positive', 'Neutral', 'Negative', 'Positive', 'Negative']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "df['Sentiment (Encoded)'] = label_encoder.fit_transform(df['Sentiment'])\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "WaX3S7ZG_0Hr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55284ec8-e6d8-4b7f-8662-88de217a8225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Review Text Sentiment  Sentiment (Encoded)\n",
            "0            The product is great!  Positive                    2\n",
            "1  The product meets expectations.   Neutral                    1\n",
            "2  The product is not as expected.  Negative                    0\n",
            "3                Love the product!  Positive                    2\n",
            "4        I don't like the product.  Negative                    0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pbup3Da3JErS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Suppose you have a dataset containing categorical data with 5 unique values. Which encoding technique would you use to transform this data into a format suitable for machine learning algorithms? Explain why you made this choice."
      ],
      "metadata": {
        "id": "b3T3ylwy_8U3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans:\n",
        "\n",
        "\n",
        "If the dataset contains categorical data with 5 unique values, and the data is nominal (meaning there is no inherent order or ranking among the categories), the preferred encoding technique would be one-hot encoding. One-hot encoding is the most suitable choice for this scenario because it avoids introducing any ordinality or artificial order among the categories.\n",
        "\n",
        "Explanation:\n",
        "\n",
        "One-Hot Encoding: One-hot encoding converts each category in the categorical variable into a binary vector, where each category is represented by a binary column. The binary column corresponding to the category takes the value 1, while all other columns take the value 0. This ensures that there is no numerical relationship or ordering among the categories.\n",
        "\n",
        "In the context of the dataset with 5 unique categorical values, one-hot encoding will create 5 binary columns, each representing one category. If a particular data point belongs to a specific category, the corresponding binary column will be set to 1, and all other binary columns will be set to 0.\n",
        "\n",
        "Example:\n",
        "\n",
        "Let's consider a dataset with a categorical variable \"Color\" that can take one of the following 5 unique values: ['Red', 'Green', 'Blue', 'Yellow', 'Orange']. Using one-hot encoding, the dataset would be transformed as follows:\n",
        "\n",
        "Color ||\tColor_Red ||\tColor_Green\t|| Color_Blue\t|| Color_Yellow\t|| Color_Orange\n",
        "\n",
        "Red\t|| 1\t|| 0\t|| 0\t|| 0\t|| 0\n",
        "\n",
        "Green\t|| 0\t|| 1\t|| 0\t|| 0\t|| 0\n",
        "\n",
        "Blue\t|| 0\t|| 0\t|| 1\t|| 0\t|| 0\n",
        "\n",
        "Yellow\t|| 0\t|| 0\t|| 0\t|| 1\t|| 0\n",
        "\n",
        "Orange\t|| 0\t|| 0\t|| 0\t|| 0\t|| 1\n",
        "\n",
        "\n",
        "In this example, one-hot encoding creates 5 binary columns, one for each color category, ensuring that there is no artificial ordering among the colors. This makes one-hot encoding the appropriate choice when dealing with nominal categorical data with 5 unique values.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y2GsTbXzJtZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Color': ['Red', 'Green', 'Blue', 'Yellow', 'Orange']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "one_hot_encoded_df = pd.get_dummies(df, columns=['Color'], prefix='Color')\n",
        "\n",
        "print(one_hot_encoded_df)"
      ],
      "metadata": {
        "id": "DEYkqoPS_0El",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc25dfdf-e13e-41b6-cca4-108301203b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Color_Blue  Color_Green  Color_Orange  Color_Red  Color_Yellow\n",
            "0           0            0             0          1             0\n",
            "1           0            1             0          0             0\n",
            "2           1            0             0          0             0\n",
            "3           0            0             0          0             1\n",
            "4           0            0             1          0             0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lp5I3A0HKcCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. In a machine learning project, you have a dataset with 1000 rows and 5 columns. Two of the columns\n",
        "are categorical, and the remaining three columns are numerical. If you were to use nominal encoding to\n",
        "transform the categorical data, how many new columns would be created? Show your calculations."
      ],
      "metadata": {
        "id": "YKMNbXYaAD7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans:\n",
        "\n",
        "If you were to use nominal encoding (label encoding) to transform the two categorical columns in the dataset, you would create a new column for each categorical feature. The number of new columns created would depend on the number of unique categories present in each categorical column.\n",
        "\n",
        "\n",
        "Assume we have the following dataset:\n",
        "\n",
        "Category 1\tCategory 2\tNumerical 1\tNumerical 2\tNumerical 3\n",
        "\n",
        "A\t             X\t        10\t         5\t         20\n",
        "\n",
        "B              Y\t        15\t          7    \t     25\n",
        "\n",
        "C\t             Z\t        12\t          6\t        18\n",
        "\n",
        "A\t             Y\t         8\t         4\t        22\n",
        "\n",
        "Step 1: Calculate the number of unique categories in each categorical column:\n",
        "\n",
        "Number of unique categories in Category 1: A, B, C (3 unique categories)\n",
        "Number of unique categories in Category 2: X, Y, Z (3 unique categories)\n",
        "\n",
        "Step 2: Calculate the number of new columns:\n",
        "\n",
        "Number of New Columns = Number of Unique Categories in Category 1 + Number of Unique Categories in Category 2\n",
        "Number of New Columns = 3 + 3 = 6\n",
        "\n",
        "So, after applying nominal encoding (one-hot encoding) to the two categorical columns, we would create 6 new columns in the dataset, each representing a unique category from either Category 1 or Category 2, using binary values (0 or 1) to indicate the presence of that category in each row.\n",
        "\n",
        "The resulting dataset after nominal encoding (one-hot encoding) would look like this:\n",
        "\n",
        "A\tB\tC\tX\tY\tZ\t  Numerical 1\t  Numerical 2\t  Numerical 3\n",
        "\n",
        "1\t0\t0\t1\t0\t0\t10\t5\t20\n",
        "\n",
        "0\t1\t0\t0\t1\t0\t15\t7\t25\n",
        "\n",
        "0\t0\t1\t0\t0\t1\t12\t6\t18\n",
        "\n",
        "1\t0\t0\t0\t1\t0\t8\t4\t22\n",
        "\n",
        "In this example, we created 6 new columns (A, B, C, X, Y, Z) representing the unique categories from Category 1 and Category 2 using one-hot encoding. Now the dataset is ready for use with machine learning algorithms, as it is entirely numerical with no categorical data."
      ],
      "metadata": {
        "id": "iTi7JpxaLdmK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dxoj3qKc_0Bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. You are working with a dataset containing information about different types of animals, including their\n",
        "species, habitat, and diet. Which encoding technique would you use to transform the categorical data into\n",
        "a format suitable for machine learning algorithms? Justify your answer."
      ],
      "metadata": {
        "id": "NvV9MrbzAIjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans:\n",
        "\n",
        "To transform the categorical data in the dataset containing information about different types of animals (species, habitat, and diet) into a format suitable for machine learning algorithms, I would use one-hot encoding. One-hot encoding is the preferred choice for this scenario because the categorical data likely does not have any inherent order or ranking, and each category is independent of others.\n",
        "\n",
        "Justification for using one-hot encoding:\n",
        "\n",
        "1.Nominal Data: The species, habitat, and diet of animals are likely nominal categorical variables, as there is no inherent order or hierarchy among the categories. For example, different animal species or habitats cannot be ranked or ordered in a meaningful way.\n",
        "\n",
        "2.Independence of Categories: One-hot encoding creates binary columns for each category, where a 1 is placed in the corresponding column if the category is present for an animal instance, and 0 is placed in all other columns. This representation ensures that each category is treated independently, avoiding the introduction of any artificial ordinality.\n",
        "\n",
        "3.Dimensionality: One-hot encoding can result in an increase in the number of columns in the dataset, but it is a suitable choice when dealing with nominal categorical data. Modern machine learning algorithms can handle high-dimensional data effectively, and one-hot encoding allows algorithms to treat each category as a separate feature.\n",
        "\n",
        "By using one-hot encoding, we can transform the categorical data into a numerical format that does not introduce any ordering or ranking, making it suitable for various machine learning algorithms. This encoding technique is widely used in practice for processing categorical data in data science and machine learning projects"
      ],
      "metadata": {
        "id": "LcpBYD3iMvzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Given example dataset\n",
        "data = {\n",
        "    'Animal': ['Lion', 'Penguin', 'Elephant', 'Tiger', 'Dolphin'],\n",
        "    'Species': ['Mammal', 'Bird', 'Mammal', 'Mammal', 'Mammal'],\n",
        "    'Habitat': ['Savanna', 'Arctic', 'Jungle', 'Jungle', 'Ocean'],\n",
        "    'Diet': ['Carnivore', 'Carnivore', 'Herbivore', 'Carnivore', 'Carnivore']\n",
        "}\n",
        "\n",
        "# Convert the dataset to a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Get the categorical columns\n",
        "categorical_columns = ['Species', 'Habitat', 'Diet']\n",
        "\n",
        "# Instantiate the OneHotEncoder\n",
        "onehot_encoder = OneHotEncoder()\n",
        "\n",
        "# Fit and transform the categorical columns using OneHotEncoder\n",
        "onehot_encoded = onehot_encoder.fit_transform(df[categorical_columns]).toarray()\n",
        "\n",
        "# Create a DataFrame for the one-hot encoded columns\n",
        "df_encoded = pd.DataFrame(onehot_encoded, columns=onehot_encoder.get_feature_names_out(input_features=categorical_columns))\n",
        "\n",
        "# Concatenate the one-hot encoded DataFrame with the original DataFrame\n",
        "df_final = pd.concat([df.drop(columns=categorical_columns), df_encoded], axis=1)\n",
        "\n",
        "# Print the result\n",
        "print(df_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpkVqkUkObCx",
        "outputId": "44b1933f-4433-481f-d598-19d9a2230c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Animal  Species_Bird  Species_Mammal  Habitat_Arctic  Habitat_Jungle  \\\n",
            "0      Lion           0.0             1.0             0.0             0.0   \n",
            "1   Penguin           1.0             0.0             1.0             0.0   \n",
            "2  Elephant           0.0             1.0             0.0             1.0   \n",
            "3     Tiger           0.0             1.0             0.0             1.0   \n",
            "4   Dolphin           0.0             1.0             0.0             0.0   \n",
            "\n",
            "   Habitat_Ocean  Habitat_Savanna  Diet_Carnivore  Diet_Herbivore  \n",
            "0            0.0              1.0             1.0             0.0  \n",
            "1            0.0              0.0             1.0             0.0  \n",
            "2            0.0              0.0             0.0             1.0  \n",
            "3            0.0              0.0             1.0             0.0  \n",
            "4            1.0              0.0             1.0             0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9dosHUXGOa_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7.You are working on a project that involves predicting customer churn for a telecommunications\n",
        "company. You have a dataset with 5 features, including the customer's gender, age, contract type,\n",
        "monthly charges, and tenure. Which encoding technique(s) would you use to transform the categorical\n",
        "data into numerical data? Provide a step-by-step explanation of how you would implement the encoding."
      ],
      "metadata": {
        "id": "jJsgNlJuAMSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans:\n",
        "\n",
        "To transform the categorical data into numerical data for predicting customer churn, we can use the following encoding techniques:\n",
        "\n",
        "Ordinal Encoding: For the \"contract type\" feature, if there is an inherent order or hierarchy among the categories (e.g., \"month-to-month\" < \"one-year\" < \"two-year\"), we can use ordinal encoding to convert the categories into numerical values while preserving their ordinal relationship.\n",
        "\n",
        "One-Hot Encoding: For the \"gender\" feature, where the categories are nominal and have no inherent order, we can use one-hot encoding to create binary columns for each category, representing the presence or absence of that category for each customer.\n",
        "\n",
        "For numerical features (\"age\", \"monthly charges\", and \"tenure\"), no encoding is necessary as they are already in numerical format.\n",
        "\n",
        "Step-by-Step Explanation:\n",
        "\n",
        "\n",
        "1.Load the Dataset: Load the dataset containing customer information, including the \"gender,\" \"age,\" \"contract type,\" \"monthly charges,\" and \"tenure\" features.\n",
        "\n",
        "\n",
        "2.Handle Missing Values: If there are any missing values in the dataset, handle them appropriately, either by imputation or removal, depending on the extent of missing data.\n",
        "\n",
        "\n",
        "\n",
        "3.Ordinal Encoding: For the \"contract type\" feature, apply ordinal encoding to convert the categories into numerical values while preserving their order. For example, \"month-to-month\" can be encoded as 1, \"one-year\" as 2, and \"two-year\" as 3.\n",
        "\n",
        "\n",
        "\n",
        "4.One-Hot Encoding: For the \"gender\" feature, apply one-hot encoding to create binary columns for each gender category. For example, if the \"gender\" feature has categories \"male\" and \"female,\" two new columns (\"gender_male\" and \"gender_female\") will be created, where a 1 represents the presence of the gender and 0 represents the absence.\n",
        "\n",
        "\n",
        "\n",
        "5.Scale Numerical Features: Since the numerical features (\"age,\" \"monthly charges,\" and \"tenure\") are of different scales, it is recommended to scale them before using them in the machine learning model. Common scaling techniques include Min-Max scaling or Standardization.\n",
        "\n",
        "\n",
        "\n",
        "6.Concatenate Encoded and Scaled Features: After encoding and scaling the relevant features, concatenate them with the original dataset to obtain a final dataset ready for machine learning.\n",
        "\n",
        "\n",
        "\n",
        "7.Split the Dataset: Split the dataset into training and testing sets for model training and evaluation.\n",
        "\n",
        "\n",
        "\n",
        "8.Build a Churn Prediction Model: Use the transformed dataset to build a churn prediction model, such as logistic regression, random forest, or support vector machine, depending on the nature of the problem and the size of the dataset.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "9.Evaluate and Fine-Tune: Evaluate the model's performance on the testing set and fine-tune the model as needed to improve its predictive capabilities.\n",
        "\n",
        "\n",
        "\n",
        "By following these steps and using appropriate encoding techniques, we can transform the categorical data into a suitable numerical format for predicting customer churn in the telecommunications company's project."
      ],
      "metadata": {
        "id": "TLWx7NTSPjR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male'],\n",
        "    'Age': [32, 45, 55, 22, 36],\n",
        "    'Contract Type': ['Month-to-Month', 'Two-Year', 'One-Year', 'Month-to-Month', 'Two-Year'],\n",
        "    'Monthly Charges': [50.0, 85.0, 70.0, 65.0, 90.0],\n",
        "    'Tenure': [6, 24, 12, 2, 48],\n",
        "    'Churn': ['Yes', 'No', 'No', 'Yes', 'No']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "contract_mapping = {'Month-to-Month': 1, 'One-Year': 2, 'Two-Year': 3}\n",
        "df['Contract Type'] = df['Contract Type'].map(contract_mapping)\n",
        "\n",
        "df = pd.get_dummies(df, columns=['Gender'], prefix='Gender')\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "numerical_features = ['Age', 'Monthly Charges', 'Tenure']\n",
        "df[numerical_features] = scaler.fit_transform(df[numerical_features])"
      ],
      "metadata": {
        "id": "ac0w0K_-_z3I"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "_t8Ds-ur_zz3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ca7d0dce-f758-435c-a44d-6bb7c0409e55"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Age  Contract Type  Monthly Charges    Tenure Churn  Gender_Female  \\\n",
              "0  0.303030              1            0.000  0.086957   Yes              0   \n",
              "1  0.696970              3            0.875  0.478261    No              1   \n",
              "2  1.000000              2            0.500  0.217391    No              0   \n",
              "3  0.000000              1            0.375  0.000000   Yes              1   \n",
              "4  0.424242              3            1.000  1.000000    No              0   \n",
              "\n",
              "   Gender_Male  \n",
              "0            1  \n",
              "1            0  \n",
              "2            1  \n",
              "3            0  \n",
              "4            1  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-ecdd5304-b7ae-431d-8461-4acd93af7129\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Contract Type</th>\n",
              "      <th>Monthly Charges</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Churn</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.303030</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.696970</td>\n",
              "      <td>3</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.478261</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.424242</td>\n",
              "      <td>3</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecdd5304-b7ae-431d-8461-4acd93af7129')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-92108f90-0a8f-4533-b6c9-188c9182e4e4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-92108f90-0a8f-4533-b6c9-188c9182e4e4')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-92108f90-0a8f-4533-b6c9-188c9182e4e4 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ecdd5304-b7ae-431d-8461-4acd93af7129 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ecdd5304-b7ae-431d-8461-4acd93af7129');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yby6CmiARFrI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jyXpyU4IRmTT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}